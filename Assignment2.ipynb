{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math \n",
    "from scipy.integrate import odeint\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics.SIRModel as SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31529ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "t = 200\n",
    "\n",
    "def gillespies_sir(t, S0, I0, R0, beta, gamma, mu):\n",
    "    times = []\n",
    "    S_list = []\n",
    "    I_list = []\n",
    "    R_list = []\n",
    "    \n",
    "    t0 = 0\n",
    "    S = S0\n",
    "    I = I0\n",
    "    R = R0\n",
    "\n",
    "    while t0 < t and (S + I + R) > 0:\n",
    "        N = S + I + R\n",
    "        r_infect = beta * S * I / N\n",
    "        r_birth = mu * N\n",
    "        r_recover = gamma * I\n",
    "        r_deathS = mu * S\n",
    "        r_deathI = mu * I\n",
    "        r_deathR = mu * R\n",
    "\n",
    "        rate0 = r_infect + r_birth + r_recover + r_deathS + r_deathI + r_deathR\n",
    "\n",
    "        if rate0 <= 0.0:\n",
    "            break\n",
    "\n",
    "        u1 = random.uniform(0, 1.0)\n",
    "        dt = -math.log(u1) / rate0\n",
    "        t0 += dt\n",
    "        if t0 > t:\n",
    "            break\n",
    "\n",
    "        u2 = random.uniform(0, 1.0) * rate0\n",
    "        if u2 < r_infect:\n",
    "            if S > 0:\n",
    "                S -= 1\n",
    "                I += 1\n",
    "        elif u2 < r_infect + r_birth:\n",
    "            S += 1\n",
    "        elif u2 < r_infect + r_birth + r_recover:\n",
    "            if I > 0:\n",
    "                I -= 1\n",
    "                R += 1\n",
    "        elif u2 < r_infect + r_birth + r_recover + r_deathS:\n",
    "            if S > 0:\n",
    "                S -= 1\n",
    "        elif u2 < r_infect + r_birth + r_recover + r_deathS + r_deathI:\n",
    "            if I > 0:\n",
    "                I -= 1\n",
    "        else:\n",
    "            if R > 0:\n",
    "                R -= 1   \n",
    "\n",
    "        times.append(t0)\n",
    "        S_list.append(S)\n",
    "        I_list.append(I)\n",
    "        R_list.append(R)\n",
    "\n",
    "    return times, S_list, I_list, R_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffe1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting:\n",
    "N_vals = [100, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Bonus part: controlling noise levels (somewhat?)\n",
    "# Plot infected fractions for different values of N: more random for smaller N\n",
    "for N in N_vals:\n",
    "    S0, I0, R0 = N - 1, 1, 0\n",
    "    times, S, I, R = gillespies_sir(t, S0, I0, R0, beta, gamma, mu)\n",
    "    fracI = np.array(I) / N # normalise since different Ns\n",
    "    plt.step(times, fracI, where='post', label=f'N={N}')\n",
    "    \n",
    "plt.title('Effects of Population Size')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Infected Fraction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Choosing N=2000 as reasonable pop size based on the plot\n",
    "N = 2000\n",
    "S0, I0, R0 = N - 1, 1, 0\n",
    "times, S, I, R = gillespies_sir(t, S0, I0, R0, beta, gamma, mu)\n",
    "fracS, fracI, fracR = np.array(S) / N, np.array(I) / N, np.array(R) / N #still doing fracrtions for consistency \n",
    "plt.step(times, fracS, where='post', label='S')\n",
    "plt.step(times, fracI, where='post', label='I')\n",
    "plt.step(times, fracR, where='post', label='R')\n",
    "plt.title('SIR Dynamics for N=2000')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population Fraction')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d725689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent deterministic ODE:\n",
    "def det_sir(y, t, beta, gamma, mu):\n",
    "    S, I, R = y\n",
    "    N = S + I + R\n",
    "    dS = mu * N - beta * S * I / N - mu * S\n",
    "    dI = beta * S * I / N - gamma * I - mu * I\n",
    "    dR = gamma * I - mu * R\n",
    "    return dS, dI, dR\n",
    "\n",
    "def integrate_det_sir(y0, t, beta, gamma, mu):\n",
    "    results = odeint(det_sir, y0, t, args=(beta, gamma, mu))\n",
    "    S, I, R = results.T\n",
    "    return S, I, R\n",
    "\n",
    "# Plot together to compare:\n",
    "plt.step(times, S_list, where='post', label='S (stochastic)')\n",
    "plt.step(times, I_list, where='post', label='I (stochastic)')\n",
    "plt.step(times, R_list, where='post', label='R (stochastic)')\n",
    "S_det, I_det, R_det = integrate_det_sir([S0, I0, R0], times, beta, gamma, mu)\n",
    "plt.plot(times, S_det, 'b--', label='S (deterministic)')\n",
    "plt.plot(times, I_det, 'r--', label='I (deterministic)')\n",
    "plt.plot(times, R_det, 'g--', label='R (deterministic)')\n",
    "plt.title('Stochastic vs Deterministic SIR')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac490dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.2\n",
    "\n",
    "# Common time grid for comparaisons:\n",
    "def nice_grid(times, sir, t_grid):\n",
    "    times = np.array(times)\n",
    "    vals = np.array(sir)\n",
    "    index = np.searchsorted(times, t_grid, side='right') - 1 # get value at or before\n",
    "    index = np.clip(index, 0, len(vals) - 1) \n",
    "    return vals[index]\n",
    "\n",
    "# Get data over multiple runs\n",
    "def ensemble(n_sims, t, dt, N, beta, gamma, mu):\n",
    "    t_grid = np.arange(0, t, dt)\n",
    "    S_ens = np.zeros((n_sims, len(t_grid)))\n",
    "    I_ens = np.zeros((n_sims, len(t_grid)))\n",
    "    R_ens = np.zeros((n_sims, len(t_grid)))\n",
    "    for i in range(n_sims):\n",
    "        S0, I0, R0 = N - 1, 1, 0\n",
    "        times, S, I, R = gillespies_sir(t, S0, I0, R0, beta, gamma, mu)\n",
    "        S_ens[i, :] = (nice_grid(times, np.array(S) / N, t_grid))\n",
    "        I_ens[i, :] = (nice_grid(times, np.array(I) / N, t_grid))\n",
    "        R_ens[i, :] = (nice_grid(times, np.array(R) / N, t_grid))\n",
    "    return t_grid, S_ens, I_ens, R_ens\n",
    "\n",
    "# Simulation variabiiity\n",
    "def get_stats(n_sims, t, dt, N, beta, gamma, mu):\n",
    "    t_grid, S_ens, I_ens, R_ens = ensemble(n_sims, t, dt, N, beta, gamma, mu)\n",
    "\n",
    "    S_mean = np.mean(S_ens, axis=0)\n",
    "    I_mean = np.mean(I_ens, axis=0)\n",
    "    R_mean = np.mean(R_ens, axis=0)\n",
    "    # std not pure variance, easier to interpret\n",
    "    S_std = np.std(S_ens, axis=0)\n",
    "    I_std = np.std(I_ens, axis=0)\n",
    "    R_std = np.std(R_ens, axis=0)\n",
    "\n",
    "    cov = ((S_ens - S_mean) * (I_ens - I_mean)).mean(axis=0)\n",
    "\n",
    "    # get deterministic sir to compare\n",
    "    S_det, I_det, R_det = integrate_det_sir([N - 1, 1, 0], t_grid, beta, gamma, mu)\n",
    "    S_det, I_det, R_det = S_det / N, I_det / N, R_det / N # normalise again\n",
    "\n",
    "    return {'t': t_grid, \n",
    "            'S_mean': S_mean, 'I_mean': I_mean, 'R_mean': R_mean,\n",
    "            'S_std': S_std, 'I_std': I_std, 'R_std': R_std,\n",
    "            'cov': cov,\n",
    "            'S_det': S_det, 'I_det': I_det, 'R_det': R_det}\n",
    "   \n",
    "# Plot\n",
    "def plot_stats(stats, title='STochastic and Deterministic means'):\n",
    "    t = stats['t']\n",
    "    I_mean, I_std, I_det = stats['I_mean'], stats['I_std'], stats['I_det']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, I_mean, color='purple', label='Mean Infected (stochastic)')\n",
    "    plt.fill_between(t, I_mean - I_std, I_mean + I_std, color='indigo', alpha=0.25, label='Â±1 Std Dev')\n",
    "    plt.plot(t, I_det, color='midnightblue', label='Mean Infected (deterministic)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Infected Fraction')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_cov(stats, title='Covariance between S and I'):\n",
    "    t = stats['t']\n",
    "    cov = stats['cov']\n",
    "    plt.figure()\n",
    "    plt.plot(t, cov, color='palevioletred')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Covariance')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "params = [\n",
    "    {'type': 'baseline', \"N\": 2000, \"beta\": 0.3, \"gamma\": 0.1, \"mu\": 0.05},\n",
    "    {'type': 'small N', \"N\": 200, \"beta\": 0.3, \"gamma\": 0.1, \"mu\": 0.05},\n",
    "    {'type': 'high beta', \"N\": 2000, \"beta\": 0.5, \"gamma\": 0.1, \"mu\": 0.05},\n",
    "    {'type': 'low beta', \"N\": 2000, \"beta\": 0.15, \"gamma\": 0.1, \"mu\": 0.05}\n",
    "]\n",
    "\n",
    "for p in params:\n",
    "    stats = get_stats(n_sims=100, t=200, dt=0.1, N=p['N'], beta=p['beta'], gamma=p['gamma'], mu=p['mu'])\n",
    "    plot_stats(stats, title=f'STochastic and Deterministic means - {p[\"type\"]}')\n",
    "    plot_cov(stats, title=f'Covariance between S and I - {p[\"type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a17de",
   "metadata": {},
   "source": [
    "# Part2 - Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75c4e5",
   "metadata": {},
   "source": [
    "## 2.1 - up until sociopattern data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59d97d",
   "metadata": {},
   "source": [
    "#### 'GENERATE NETWORKS OF EQUIVALENT FORM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4db205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters ('similar characteristics')\n",
    "N=1000\n",
    "avg_k = 10\n",
    "\n",
    "# pretty colors for plots...\n",
    "colors = {\n",
    "    'Erdos-Renyi': 'rebeccapurple',\n",
    "    'Watts-Strogatz': 'darkslategray',\n",
    "    'Barabasi-Albert': 'hotpink'\n",
    "}\n",
    "\n",
    "\n",
    "# Create networks\n",
    "def make_ws(N, k, seed, p=0.1):\n",
    "    return nx.watts_strogatz_graph(N, k, p, seed=seed) \n",
    "\n",
    "def make_er(N, avg_k, seed):\n",
    "    p = avg_k / (N - 1)\n",
    "    return nx.erdos_renyi_graph(N, p, seed=seed)\n",
    "\n",
    "def make_ba(N, avg_k, seed):\n",
    "    m = avg_k // 2  \n",
    "    return nx.barabasi_albert_graph(N, m, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "## METRICS AND STATS:\n",
    "\n",
    "# basic measures:\n",
    "def get_measures(G, name):\n",
    "    k = np.array([d for _, d in G.degree()])\n",
    "    cc = np.fromiter(nx.clustering(G).values(), dtype=float)\n",
    "    stats= {\n",
    "        'name': name,\n",
    "        'nodes' : G.number_of_nodes(),\n",
    "        'edges' : G.number_of_edges(),\n",
    "        'avg_degree' : k.mean(),\n",
    "        'diameter' : nx.diameter(G) if nx.is_connected(G) else float('inf'),\n",
    "        'avg_shortest_path': nx.average_shortest_path_length(G) if nx.is_connected(G) else float('inf'),\n",
    "        'avg_clustering_coeff' : nx.average_clustering(G),\n",
    "    }\n",
    "    return stats, k, cc\n",
    "        \n",
    "\n",
    "# deg dist\n",
    "def plot_dd(k_data):\n",
    "    # PDF hist\n",
    "    plt.figure()\n",
    "    for name, k in k_data.items():\n",
    "        plt.hist(k, bins=range(0, max(k)+2), density=True, label=name, alpha=0.5, color=colors[name]) \n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('P(k)')\n",
    "    plt.title('Degree Distribution (PDF)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # CCDF plot\n",
    "    plt.figure()\n",
    "    for name, k in k_data.items():\n",
    "        sorted_k = np.sort(k)\n",
    "        ccdf = 1 - np.arange(1, len(sorted_k) + 1) / len(sorted_k)\n",
    "        plt.loglog(sorted_k, ccdf, marker='.', linestyle='none', label=name, alpha=0.5, color=colors[name])\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('Degree Distribution (CCDF)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# clustering dist\n",
    "def plot_cc(cc_data):\n",
    "    plt.figure()\n",
    "    for name, cc in cc_data.items():\n",
    "        plt.hist(cc, bins=30, density=True, alpha=0.5, label=name, color=colors[name])\n",
    "    plt.xlabel('Clustering Coefficient')\n",
    "    plt.ylabel('P(c)')\n",
    "    plt.title('Clustering Coefficient Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# centralities:\n",
    "def get_centralities(G):\n",
    "    deg_cent = np.fromiter(nx.degree_centrality(G).values(), dtype=float)\n",
    "    btw_cent = np.fromiter(nx.betweenness_centrality(G, normalized=True).values(), dtype=float)\n",
    "    clos_cent = np.fromiter(nx.closeness_centrality(G).values(), dtype=float)\n",
    "    ev_cent = np.fromiter(nx.eigenvector_centrality_numpy(G).values(), dtype=float)\n",
    "    return deg_cent, btw_cent, clos_cent, ev_cent\n",
    "\n",
    "\n",
    "def plot_centralities(cent_data):\n",
    "    cent_names = ['Degree Centrality', 'Betweenness Centrality', 'Closeness Centrality', 'Eigenvector Centrality']\n",
    "    for i, cent_name in enumerate(cent_names):\n",
    "        plt.figure()\n",
    "        for name, cents in cent_data.items():\n",
    "            cent = cents[i]\n",
    "            plt.hist(cent, bins=50, density=True, alpha=0.5, label=name, color=colors[name])\n",
    "        plt.xlabel(cent_name)\n",
    "        plt.ylabel('P(c)')\n",
    "        plt.title(f'{cent_name} Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4846f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic comparaisons:\n",
    "networks = {\n",
    "    'Erdos-Renyi': make_er(N, avg_k, 42),\n",
    "    'Watts-Strogatz': make_ws(N, avg_k, 42, p=0.1),\n",
    "    'Barabasi-Albert': make_ba(N, avg_k, 42)\n",
    "}\n",
    "sums = []\n",
    "k_data = {}\n",
    "cc_data = {}\n",
    "cent_data = {}\n",
    "\n",
    "for name, G in networks.items():\n",
    "    s, k, cc = get_measures(G, name)\n",
    "    sums.append(s)\n",
    "    k_data[name] = k\n",
    "    cc_data[name] = cc\n",
    "    cent_data[name] = get_centralities(G)\n",
    "\n",
    "measures_df = pd.DataFrame(sums)\n",
    "print(\"network measures:\")\n",
    "print(measures_df)\n",
    "\n",
    "# plot\n",
    "plot_dd(k_data)\n",
    "plot_cc(cc_data)\n",
    "plot_centralities(cent_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580163a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Varying params:\n",
    "# not comparing all measures this time, just specific ones for diff topologies\n",
    "seed = range(1, 11)\n",
    "\n",
    "def get_specifics(G):\n",
    "    k = np.array([d for _, d in G.degree()])\n",
    "    return {\n",
    "        'avg_degree': k.mean(),\n",
    "        'degree_var': k.var(),\n",
    "        'C': nx.average_clustering(G),\n",
    "        'L': nx.average_shortest_path_length(G) if nx.is_connected(G) else float('inf')\n",
    "    }\n",
    "\n",
    "def vary_ws(N, k, p_values, seeds):\n",
    "    data = []\n",
    "    for p in p_values:\n",
    "        for s in seeds:\n",
    "            G = make_ws(N, k, s, p)\n",
    "            m = get_specifics(G)\n",
    "            m.update({'p': p, 'seed': s})\n",
    "            data.append(m)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def vary_er(N, k_values, seeds):\n",
    "    data = []\n",
    "    for k in k_values:\n",
    "        for s in seeds:\n",
    "            G = make_er(N, k, s)\n",
    "            m = get_specifics(G)\n",
    "            m.update({'avg_k': k, 'seed': s})\n",
    "            data.append(m)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def vary_ba(N, m_values, seeds):\n",
    "    data = []\n",
    "    for m in m_values:\n",
    "        for s in seeds:\n",
    "            G = nx.barabasi_albert_graph(N, m, seed=s)\n",
    "            mtr = get_specifics(G)\n",
    "            mtr.update({'m': m, 'seed': s})\n",
    "            data.append(mtr)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "ws_df = vary_ws(N, avg_k, [0.01, 0.1, 0.5], seed)\n",
    "er_df = vary_er(N, [6, 10, 20], seed)\n",
    "ba_df = vary_ba(N, [2, 5, 10], seed)\n",
    "\n",
    "# Plot mean +std\n",
    "def plot_ens(df, xcol, ycol, label, color):\n",
    "    grouped = df.groupby(xcol)[ycol]\n",
    "    x = grouped.mean().index\n",
    "    x = np.sort(x)\n",
    "    y_mean = grouped.mean().values\n",
    "    y_std = grouped.std().values\n",
    "    plt.plot(x, y_mean, 'o-', color=color, label=label)\n",
    "    plt.fill_between(x, y_mean - y_std, y_mean + y_std, color=color, alpha=0.2)\n",
    "\n",
    "plt.figure()\n",
    "plot_ens(ws_df, 'p', 'C', 'WS Clustering', 'darkslategray')\n",
    "plot_ens(ws_df, 'p', 'L', 'WS Path Length', 'hotpink')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Rewiring probability (p)')\n",
    "plt.ylabel('Measure value')\n",
    "plt.title('WS networks: mean Â± std across 10 runs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plot_ens(er_df, 'avg_k', 'C', 'ER Clustering', 'darkslategray')\n",
    "plot_ens(er_df, 'avg_k', 'L', 'ER Path Length', 'hotpink')\n",
    "plt.xlabel('Average degree â¨kâ©')\n",
    "plt.ylabel('Metric value')\n",
    "plt.title('EER networks: mean Â± std across 10 seeds')\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_ens(ba_df, 'm', 'degree_var', 'BA degree variance', 'rebeccapurple')\n",
    "plot_ens(ba_df, 'm', 'C', 'BA clustering', 'darkslategray')\n",
    "plt.xlabel('m (new links per node)')\n",
    "plt.ylabel('Measure value')\n",
    "plt.title('BA networks: mean Â± std across 10 runs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1c332",
   "metadata": {},
   "source": [
    "### Implement and simulate part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementations and stats\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def initial_nodes(G, k, strategy='rand'):\n",
    "    if strategy == 'rand':\n",
    "        return np.random.choice(G.nodes(), k, replace=False).tolist()\n",
    "    elif strategy == 'high_deg':\n",
    "        degree_dict = dict(G.degree())\n",
    "        sorted_nodes = sorted(degree_dict, key=degree_dict.get, reverse=True)\n",
    "        return sorted_nodes[:k]\n",
    "    elif strategy == 'eigen':\n",
    "        ev_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "        sorted_nodes = sorted(ev_centrality, key=ev_centrality.get, reverse=True)\n",
    "        return sorted_nodes[:k]\n",
    "    elif strategy == 'cluster':\n",
    "        node = np.random.choice(G.nodes())\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        choice = [node] + neighbors[:max(0, k - 1)]\n",
    "        if len(choice) < k:\n",
    "            oth = list(set(G.nodes()) - set(choice))\n",
    "            choice += list(np.random.choice(oth, k - len(choice), replace=False))\n",
    "        return choice\n",
    "    else:\n",
    "        raise ValueError(\"??\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Run and get results:\n",
    "def run_single_sir(G, beta, gamma, infected_nodes, max_iter, seed):\n",
    "    set_all_seeds(seed) # keeping same\n",
    "\n",
    "    # build\n",
    "    model = SIR(G)\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_initial_configuration(\"Infected\", infected_nodes)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    # get reults\n",
    "    iters = model.iteration_bunch(max_iter)\n",
    "    node_counts = [i.get('node_count', {0: 0, 1: 0, 2: 0}) for i in iters]\n",
    "    node_count = np.array([[d.get(0, 0), d.get(1, 0), d.get(2, 0)] for d in node_counts])\n",
    "\n",
    "    N = G.number_of_nodes()\n",
    "    t = np.arange(len(node_count))\n",
    "    S, I, R = node_count[:, 0] / N, node_count[:, 1] / N, node_count[:, 2] / N\n",
    "\n",
    "    series = pd.DataFrame({'t': t, 'S': S, 'I': I, 'R': R})\n",
    "    return iters, series\n",
    "\n",
    "\n",
    "# Ensemble and stats:\n",
    "\n",
    "# helper\n",
    "def stats_series(df):\n",
    "    return{\n",
    "    'peak_I': df['I'].max(),\n",
    "    'time_to_peak': df.loc[df['I'].idxmax(), 't'],\n",
    "    'final_frac_R': df['R'].iloc[-1]\n",
    "    }\n",
    "\n",
    "# Run ensemble\n",
    "def ensemble_nx(n_sims, G, beta, gamma, k, strategy, max_iter, seed):\n",
    "    series = []\n",
    "    stats_a =[]\n",
    "    for i in range(n_sims):\n",
    "        init_n = initial_nodes(G, k, strategy=strategy)\n",
    "    \n",
    "        _, s = run_single_sir(G, beta, gamma, init_n, max_iter, seed+i)\n",
    "        series.append(s)\n",
    "        stats_a.append(stats_series(s))\n",
    "    \n",
    "    # matrices\n",
    "    t = series[0]['t'].values\n",
    "    S_ens = np.vstack([s['S'].values for s in series])\n",
    "    I_ens = np.vstack([s['I'].values for s in series])\n",
    "    R_ens = np.vstack([s['R'].values for s in series])\n",
    "\n",
    "    stats = dict(\n",
    "        t=t,\n",
    "        S_mean=S_ens.mean(0), S_std=S_ens.std(0),\n",
    "        I_mean=I_ens.mean(0), I_std=I_ens.std(0),\n",
    "        R_mean=R_ens.mean(0), R_std=R_ens.std(0)\n",
    "    )\n",
    "\n",
    "    return series, stats, pd.DataFrame(stats_a)\n",
    "\n",
    "\n",
    "def plot_I_stats(stats, title='Infected Fraction over Time'):\n",
    "    t = stats['t']\n",
    "    I_mean = stats['I_mean']\n",
    "    I_std = stats['I_std']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, I_mean, color='hotpink', label='Mean Infected')\n",
    "    plt.fill_between(t, I_mean - I_std, I_mean + I_std, color='rebeccapurple', alpha=0.25, label='std')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Infected Fraction')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3432ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "betas = [0.02, 0.04, 0.06]\n",
    "gammas = [0.02, 0.05]\n",
    "max_iter = 200\n",
    "n_runs = 100\n",
    "strats = ['rand', 'high_deg', 'eigen', 'cluster']\n",
    "ks = [1, 5, 10]\n",
    "base = 42\n",
    "\n",
    "\n",
    "networks = {\n",
    "    'ER': make_er(N=1000, avg_k=10, seed=1),\n",
    "    'WS': make_ws(N=1000, k=10, seed=1, p=0.1),\n",
    "    'BA': make_ba(N=1000, avg_k=10, seed=1)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, G in networks.items():\n",
    "    for beta in betas:\n",
    "        for gamma in gammas:\n",
    "            for strat in strats:\n",
    "                for k in ks:\n",
    "                    series, stats, summary = ensemble_nx(\n",
    "                        n_sims=n_runs,\n",
    "                        G=G,\n",
    "                        beta=beta,\n",
    "                        gamma=gamma,\n",
    "                        k=k,\n",
    "                        strategy=strat,\n",
    "                        max_iter=max_iter,\n",
    "                        seed=base \n",
    "                    )\n",
    "                    \n",
    "                    results.append({\n",
    "                        'network': name,\n",
    "                        'beta': beta,\n",
    "                        'gamma': gamma,\n",
    "                        'strategy': strat,\n",
    "                        'init_k': k,\n",
    "                        'peak_I_mean': summary['peak_I'].mean(),\n",
    "                        't_peak_mean': summary['time_to_peak'].mean(),\n",
    "                        'final_R_mean': summary['final_frac_R'].mean()\n",
    "                    })\n",
    "                    \n",
    "                    plot_I_stats(\n",
    "                        stats,\n",
    "                        title=f\"{name} Network, Î²={beta}, Î³={gamma}, init_strategy={strat}, k={k}\"\n",
    "                    )\n",
    "\n",
    "# combine\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "627466eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 374 nodes and 1265 edges\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv(\"transmission_network.csv\", sep=\";\")\n",
    "A = df.drop(columns=[\"Unnamed: 0\"]).to_numpy(dtype=float)\n",
    "A[A > 0] = 1 # hope i converted correctly??\n",
    "G = nx.from_numpy_array(A)\n",
    "print(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
